{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| Fabrice Jimenez | <a href=\"https://supaerodatascience.github.io/deep-learning/\">https://supaerodatascience.github.io/deep-learning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - Practical Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is following the progression of the Dimensionality Reduction class. It provides practical illustrations in Python  to understand the notions we have seen in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Author: Fabrice JIMENEZ\n",
    "    \n",
    "Link to course materials: https://github.com/jfabrice/ml-class-dimensionality-reduction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary loading with Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using this notebook with Google Colab, please execute first the following cells, to retrieve the GitHub repository content. Otherwise, ignore these cells and move to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c https://github.com/SupaeroDataScience/deep-learning/blob/main/DR/data/mnist_test.csv?raw=true -O data/mnist_test.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use for this application is the famous MNIST dataset (handwritten digits). We use the CSV version of this dataset available here: https://pjreddie.com/projects/mnist-in-csv/ \n",
    "\n",
    "We will keep only the mnist_test.csv file, containing 10 000 gray-scale images of dimension 28 x 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mnist_test.csv', header=None)\n",
    "df['pixels'] = df.index.map(lambda x: np.array(df.iloc[x][1:]))\n",
    "dropcols = df.columns[(df.columns != 0) * (df.columns != 'pixels')]\n",
    "df.drop(dropcols, axis=1, inplace=True)\n",
    "df.columns = ['label','pixels']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.imshow(df['pixels'][2].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "source": [
    "## Dimensionality reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will think about how to distinguish the characteristics of different handwritten digits, starting only from the raw values of the pixels as features.\n",
    "\n",
    "Let's consider 3 digits. Keep them as they are for the moment, you will have time at the end to play with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Digits considered here ##\n",
    "labels = [1,6,8]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "X = np.array([df['pixels'][i] for i in df.index if df['label'][i] in labels])\n",
    "y = np.array([df['label'][i] for i in df.index if df['label'][i] in labels])\n",
    "\n",
    "print('X shape: '+str(X.shape))\n",
    "print('y shape: '+str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 28 x 28 = 784 features. It is a high dimension (~ same order of magnitude as the number of points). \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Question: How would you visualize the behavior of the different classes (digits), or find a direction, important features contributing to these classes?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we cannot rely on univariate analysis: it is quite clear that the value of a given pixel on the image will not determine by itself the number which is written. You need to study the relationship between the pixel values: let's see how the methods to reduce dimensionality we saw during this course can help us distinguish noise, correlation and information patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Components Analysis: linear approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the PCA\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "XPCA = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the axes you want to visualize\n",
    "component_x = 1\n",
    "component_y = 2\n",
    "\n",
    "## Plotting\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(labels)):\n",
    "    ax.scatter(XPCA[y == labels[i],component_x-1], XPCA[y == labels[i],component_y-1], c=colors[i], label=labels[i], alpha=0.4)\n",
    "\n",
    "l = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: Try to visualize different axes and find the ones who allow (or not) to distinguish the classes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-distributed Stochastic Neighbor Embedding: non-linear approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the t-SNE 2D projection\n",
    "\n",
    "## Parameters with real influence on the accuracy\n",
    "perplexity = 30\n",
    "learning_rate = 200\n",
    "n_iter = 1000\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=n_iter)\n",
    "XTSNE = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(labels)):\n",
    "    ax.scatter(XTSNE[y == labels[i],0], XTSNE[y == labels[i],1], c=colors[i], label=labels[i], alpha=0.4)\n",
    "l = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: Try to visualize the projection by choosing different parameter values. What is the advantage of t-SNE over PCA? What is the inconvenient?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact on supervised model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we consider a supervised Machine Learning model to predict the class of an image (which digit it corresponds to). We will study the impact of dimensionality reduction on 3 classifiers which have different mechanisms:\n",
    "- Naive Bayes Classifier (nb)\n",
    "- SVM Classifier (svm)\n",
    "- Random Forest Classifier (rf)\n",
    "\n",
    "We can give them as features 3 different inputs:\n",
    "- All the pixel values (raw)\n",
    "- The n first PCA components (10 for example)\n",
    "- The 2 dimensions from t-SNE projection (tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_my_model(model, features, test_size):\n",
    "    \n",
    "    ## Building train and test sets from features\n",
    "    if features == 'raw':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    elif features == 'tsne':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(XTSNE, y, test_size=test_size)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(XPCA[:,:features], y, test_size=test_size)\n",
    "\n",
    "    print(\"Training samples: \"+str(X_train.shape[0]))\n",
    "    print(\"Testing samples: \"+str(X_test.shape[0]))\n",
    "    print(\"Number of features: \"+str(X_train.shape[1]))\n",
    "    \n",
    "    ## Fitting model\n",
    "    if model == 'nb':\n",
    "        clf = GaussianNB()\n",
    "    elif model == 'svm':\n",
    "        clf = SVC(gamma='auto')\n",
    "    elif model == 'rf':\n",
    "        clf = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=None, max_features=np.min([10, X_train.shape[1]]))\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    ## Printing scores\n",
    "    learningScore = clf.score(X_train, y_train)\n",
    "    generalizationScore = clf.score(X_test, y_test)\n",
    "    print('Learning score: '+str(learningScore))\n",
    "    print('Generalization score: '+str(generalizationScore))\n",
    "    \n",
    "    return generalizationScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: Experiment in the cell below by using the function fit_my_model, to check the scores for different configurations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'svm' ## svm, nb, rf\n",
    "features = 'raw' ## raw, tsne, or Integer corresponding to the n first PCA components\n",
    "test_size = 0.2\n",
    "\n",
    "score = fit_my_model(model, features, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: What is the effect of dimensionality reduction on the 3 classifiers? Try to explain why with your intuition...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test all the configurations and build a result table with test scores, to help you answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table = pd.DataFrame(columns = ['raw', 'pca', 'tsne'], index=['svm', 'nb', 'rf'])\n",
    "for f in comparison_table.columns:\n",
    "    for m in comparison_table.index:\n",
    "        print(f + ' - ' + m)\n",
    "        comparison_table.loc[m,f] = fit_my_model(m, f if f!='pca' else 10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heatmap with summarized results\n",
    "fig = sns.heatmap(comparison_table.astype('float'), annot=True, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: What conclusions can you give? If you have time left, you can try with different sets of digits.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples concern supervised classifiers only. Can you imagine the impact on other tasks: regression, clustering, anomaly detection... ?"
   ]
  },
  {
   "source": [
    "## Autoencoders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this section we will build step by step an Autoencoder architecture, train it and evaluate it on MNIST data. First, it will be a standard fully connected autoencoder, then a variational autoencoder in the next section.\n",
    "\n",
    "To prepare this work, let's import the appropriate libraries and use the full MNIST dataset from Keras, as Neural Networks will need more data for training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = np.array([x.flatten() for x in X_train]).astype(\"float32\") / 255.\n",
    "X_test = np.array([x.flatten() for x in X_test]).astype(\"float32\") / 255.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "source": [
    "In this case we have normalized the pixel values between 0 and 1, to help neural network modelling (sigmoid) and training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Standard Autoencoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this first part, let's implement a standard autoencoder (fully-connected) with 1 hidden layer (200 units, ReLU activation) before the latent space (10 units, ReLU activation). Let's begin with the separate architectures for encoder and decoder. Be careful with the final layer activation!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CODE HERE ######\n",
    "\n",
    "# Encoder architecture\n",
    "encoder_inputs = keras.Input(shape=(784,))\n",
    "hidden1 = ###\n",
    "latent_space = ###\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, latent_space, name=\"encoder\")\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CODE HERE ######\n",
    "\n",
    "# Decoder architecture\n",
    "decoder_inputs = keras.Input(shape=(10,))\n",
    "hidden2 = ###\n",
    "decoder_outputs = ###\n",
    "\n",
    "decoder = keras.Model(decoder_inputs, decoder_outputs, name=\"decoder\")\n",
    "#######################"
   ]
  },
  {
   "source": [
    "Now, we combine them to build the full autoencoder."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining architectures\n",
    "outputs = decoder(latent_space)\n",
    "autoencoder = keras.Model(encoder_inputs, outputs, name=\"autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "source": [
    "Now we need to define the loss function for training. In the case of MNIST images, we can use a pixelwise binary cross-entropy, summed up over the image. We could also use a mean squared error, let's leave it as an exercise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function definition\n",
    "reconstruction_loss = keras.losses.binary_crossentropy(encoder_inputs, outputs) * 784\n",
    "\n",
    "autoencoder_loss = K.mean(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "autoencoder.add_loss(autoencoder_loss)\n",
    "autoencoder.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CODE HERE ######\n",
    "\n",
    "# Fitting the model\n",
    "history = autoencoder.fit(###, ###,\n",
    "          epochs=30,\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          validation_data=(###, ###))\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training and validation losses\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "source": [
    "We seem to obtain a pretty reasonable training process! Let's visualize the quality of reconstructed images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap=\"gray\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    encoded_img = encoder.predict(np.array([X_test[i]]).reshape(1,784))\n",
    "    decoded_img = decoder.predict(encoded_img).reshape(28, 28)\n",
    "    plt.imshow(decoded_img, cmap=\"gray\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We can see that some details are lost, but the global shapes are correctly reconstructed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Variational Autoencoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this second part, let's implement a variational autoencoder. Let's begin by defining the specific layer we will use to sample values from the gaussian distribution defined by the latent space means and standard deviations (z_mean, z_logvar)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CODE HERE ######\n",
    "\n",
    "# Coding the specific sampling layer as a Keras Layer object\n",
    "class Sampling(layers.Layer):\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_logvar = inputs\n",
    "\n",
    "        nbatch = K.shape(z_mean)[0]\n",
    "        ndim = K.shape(z_mean)[1]\n",
    "\n",
    "        std = K.exp(z_logvar)\n",
    "        eps = K.random_normal(shape=(nbatch,ndim), mean=0., stddev=0.1)\n",
    "        \n",
    "        z = ###\n",
    "\n",
    "        return z\n",
    "\n",
    "#######################"
   ]
  },
  {
   "source": [
    "Let's write now the separate encoder and decoder architectures. Be careful, no activation function for mean and logvar computation..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CODE HERE ######\n",
    "\n",
    "# Encoder architecture\n",
    "encoder_inputs = keras.Input(shape=(784,))\n",
    "hidden1 = layers.Dense(200, activation=\"relu\")(encoder_inputs)\n",
    "\n",
    "z_mean = ###\n",
    "z_logvar = ###\n",
    "\n",
    "# Sampling\n",
    "z = Sampling()([z_mean, z_logvar])\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder architecture\n",
    "decoder_inputs = keras.Input(shape=(10,))\n",
    "decoder_hidden = layers.Dense(200, activation=\"relu\")(decoder_inputs)\n",
    "decoder_outputs = layers.Dense(784, activation=\"sigmoid\")(decoder_hidden)\n",
    "\n",
    "decoder = keras.Model(decoder_inputs, decoder_outputs, name=\"decoder\")"
   ]
  },
  {
   "source": [
    "Now, we combine them to build the full autoencoder."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining architectures\n",
    "outputs = decoder(z)\n",
    "vae = keras.Model(encoder_inputs, outputs, name=\"vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "source": [
    "Now we need to define the loss function for training. As reconstruction loss, we can still use the pixelwise binary cross-entropy, summed up over the image. In the case of VAE, there is an additional term to the loss: the Kullback-Leibler divergence. Write this new term, using the keras backend functions: K.square, K.exp, K.sum..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CODE HERE ######\n",
    "\n",
    "# Loss function definition\n",
    "reconstruction_loss = keras.losses.binary_crossentropy(encoder_inputs, outputs) * 784\n",
    "\n",
    "kl_loss = ###\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "history = vae.fit(X_train, X_train,\n",
    "          epochs=30,\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training and validation losses\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "source": [
    "We seem to obtain a pretty reasonable training process! Let's visualize the quality of reconstructed images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap=\"gray\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    encoded_img = encoder.predict(np.array([X_test[i]]).reshape(1,784))\n",
    "    decoded_img = decoder.predict(encoded_img).reshape(28, 28)\n",
    "    plt.imshow(decoded_img, cmap=\"gray\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We can see that some details are lost, but the global shapes are correctly reconstructed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Since a VAE uses a generative model, we can use the decoder to build fake images, and we can see that the latent space is continuous! Let's sample some random images in a given range of latent space values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 generated images\n",
    "figure = np.zeros((28 * n, 28 * n))\n",
    "\n",
    "# We sample n images within [-15, 15] standard deviations, around 0 mean\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        \n",
    "        # We sample the latent space over the 2 first neurons, feel free to change that to other pairs!\n",
    "        z_sample = np.array([[xi, yi, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "\n",
    "        digit = x_decoded[0].reshape(28, 28)\n",
    "        figure[i * 28: (i + 1) * 28,\n",
    "               j * 28: (j + 1) * 28] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Exercise: if you had to detect an abnormal image (for example: not a digit) in this 1D dataset, how would you do?\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Try to introduce a gray-scale 28x28 image of your choice in the dataset (picture of your cat...). Shuffle the dataset, and test your anomaly detection method to find it!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always think first about the principles, the intuition, the qualitative aspect behind all the available functions you can find online.\n",
    "\n",
    "- Many people can chain very complex algorithms together and get results which might be relevant for a problem.\n",
    "- Only a few can make the right choices to quickly optimize the resolution of a problem and assess its feasability..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
